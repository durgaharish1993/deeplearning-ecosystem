
### 1. Quantization 


### 2. Training and Latency 
- Flash Attention 

- KV Cache 

- positional Embeeding 
    - Absoulte positional embeeding 
    - Relative positional Embeeding 
    - Rotarty Positional embeeding 

- MHA, MQA, GQA 
    - Multi head attention 
    - Multi query attention 
    - Grouped query attention 


